# 메모리 구조

## Stack Memory

스택은 LIFO로 작동하는 지역 메모리

### 특성:

- 빠른 할당과 해제: 할당이 매우 빠름 단순히 스택 포인터를 옮기기만 하면 됨
- 자동 관리: 함수가 시작/종료 될 때 자동으로 할당 및 제거됨
- 연속적인 메모리 영역: 변수들이 연속적인 메모리 블럭에 저장됨
- 개별 스레드마다 각각의 스택 메모리를 가짐

### 스택에 저장되는 것들:

- 지역변수
- 함수의 파라메터
- 값을 리턴해줄 주소
- 호출된 함수의 정보 (스택 프레임)
- CPU 레지스터 (컨텍스트 스위칭 동안)

## Heap Memory

힙은 메모리를 동적으로 할당하기 위해 존재하는 영역

### 특성:

- 느린 할당/회수: 조각들을 관리하고 메모리 블록을 검색해야 함 (공간 탐색)
- 수동 관리: GC가 따로 없다면 기본적으로 프로그래머가 직접 관리해야됨 (C의 malloc)
- 불연속적인 메모리 영역: 힙 영역 내에 단편화된 메모리 조각들이 존재
- 자원 공유: 모든 스레드들이 같은 힙 메모리를 공유함

### 힙에 저장되는 것들:

- 동적으로 할당되는 객체들
- 컴파일 타임에 크기를 알 수 없는 객체들
- 함수의 스코프 밖에서도 유지되어야 하는 객체들

## Visualization

```
High Memory Addresses
┌─────────────────────┐
│       Stack         │ ← 스택은 아래로 커짐 (스택 포인터)
│  (Local variables,  │
│   function calls)   │
├─────────────────────┤
│         ↓           │
│    (Free space)     │
│         ↑           │
├─────────────────────┤
│       Heap          │ ← 힙은 위로 커짐
│  (Dynamic memory)   │
├─────────────────────┤
│    Uninitialized    │
│      Data (BSS)     │
├─────────────────────┤
│    Initialized      │
│       Data          │
├─────────────────────┤
│    Text Segment     │
│   (Program code)    │
└─────────────────────┘
Low Memory Addresses

```

## Differences

|  | **스택** | **힙** |
| --- | --- | --- |
| 속도 | 매우 빠름 | 상대적으로 느림 |
| 관리 | 자동 | 수동 |
| 실제 크기 | 제한적 (MB 단위) | 매우 큼 (GB 단위) |
| 단편화 | 불가 | 가능 |
| 액세스 패턴 | LIFO | 랜덤 액세스 |
| 스레드 안전성 | 스레드마다 각각 존재 | 공유됨, 동기화 필요 |


# 심화주제

## 스택과 힙 메모리는 서로의 반대 방향에서 점점 커짐
1. 용량이 점점 증가하다 서로 충돌하면 어떻게 되는가?
	1. 힙 오버플로우
	2. 스택 오버플로우

## 스택 오버플로우를 유발 할 수 있는 상황은 무엇이 있을까
1. 무한반복되는 재귀함수
	1. 자바가 이것을 자동으로 감지하지 않는 이유?
		1. 컴파일 타임에는 알 수가 없음 ([Halting Problem](https://en.wikipedia.org/wiki/Halting_problem))
		2. 자바가 할 수 있는건 스택이 꽉 찼을때 예외 던지기 뿐...
2. 깊은 메소드 콜 체인
	1. 스프링 같은 프레임워크들이 잘 보이지 않는 깊은 호출 체인을 유발
		1. AOP 프록시 체인: @Transactional + @Security + @Cache + ...
		2. 의존성 주입 체인: A -> B -> C -> D -> A (순환 참조)
		3. 이벤트 처리: ApplicationEvent -> Listener -> 또 다른 이벤트 -> ...
3. 초대형 로컬 변수들
	1. 로컬에 선언된 대형 배열이 소모하는 스택 공간
		1. 100만개의 정수 배열을 선언하는 순간 최소 4MB의 공간이 스택에 잡힘
4. Thread-specific nature
	1. 모든 스레드가 각자의 스택 공간을 가지기에, 멀티 스레딩은 사용 가능한 스택 공간에 영향을 줌
		1. 스레드를 백만개쯤 생성한다면?
			1. 실제로는 불가능함 OS에서 프로세스당 스레드 갯수 제한을 둠
			2. 가능했다면 스레드 하나당 1MB 스택을 부여한다고 쳤을때 1TB 메모리 필요

## 힙 오버플로우를 유발 할 수 있는 상황은 무엇이 있을까
1. 정적 참조를 통한 memory leak
	1. 정리되지 않은 컬렉션
		1. static으로 선언된 컬렉션에 지속적으로 데이터 주입시 참조가 끊어지지 않음
2. 반복적인 스트링 concat
	1. StringBuilder / StringBuffer 최적화 없이
	2. 단순 join으로 연결되어 반복적으로 새 String object를 생성하고 값을 옮겨 담을때
		1. 특히 반복문으로 string join을 다룰때
3. Off-heap 메모리
	1. 일반적으로 가비지 컬렉션에 잡히지 않는 다이렉트 ByteBuffers
		1. GC의 관리영역 바깥에 존재하는 관계로 삭제되지 않음

## 메모리 압력 시나리오
1. 가비지 콜렉터로 메모리를 감당 할 수 없는 경우 어떻게 되는가?
	1. 터지는거지 뭐...
2. 메모리 부족으로 스택 또는 힙 오버플로우가 예상된다면, JVM은 어떻게 작동하는가?
	1. 스택 오버플로우의 경우 현재 스레드의 실행을 즉시 중단
		1. StackOverflowError 에러 발생
		2. Error 클래스를 상속받아 catch 해서 복구 할 수 없음
	2. 힙 오버플로우의 경우 가비지 컬렉션 시도
		1. GC 시도 이후에도 메모리 공간이 부족한 경우 OutOtMemoryError 발생

## JVM 실행 옵션 -Xss -Xmx가 의미하는것
1. 혹시 마인크래프트를 해보셨나요? 그럼 봤을지도
	1. Xss 옵션은 스택, Xmx 옵션은 힙 메모리의 용량을 의미

## 객체의 생명주기 (스택 → 힙 → GC)가 퍼포먼스에 미치는 영향
1. 스택에는 메서드 호출로 인한 local/referral variable이 저장됨
2. 객체의 경우 스택에 저장되는건 객체의 참조(포인터)만 → 실제 객체는 힙에 있음
3. 참조 접근 비용은 매우 낮지만 객체 생성 비용은 힙의 영향을 받음
4. 힙은 실제 객체의 데이터가 저장되는 영역이며 GC가 관리함
5. 많은 객체가 힙에 생성되면 GC가 자주 발생하며 퍼포먼스 저하 가능
6. 가비지컬렉션은 사용되지 않는 객체를 찾아서 메모리에서 제거함
7. 제거하는동안 참조 안전성을 보장하기 위해 모든 스레드를 일시정지 (Stop the World)
8. 힙 할당이 많으면 GC 또한 많이 발생하며 이를 위해 스레드가 정지되는 시간도 길어짐
9. 생성된지 얼마 안 된 객체 (young) / 생성된지 오래된 객체 (old)에 따라서 GC가 다른 접근을 취한다고 알고 있는데 까먹었음
	1. 객체 생성시 코스트
		1. 힙에 영향 받지만 단순 참조 접근은 스택 참조라 저렴함
	2. 객체 소멸시 코스트
		1. GC를 통해 모든 스레드 일시정지 및 참조 계산이 필요하므로 상당히 비쌈
	3. 같은 객체를 계속해서 생성/소멸시켜야 한다면 오브젝트 풀을 활용하는 방법도 있다
	4. 원시타입을 최대한 활용하는 방법도 가능
	5. 객체 생성 패턴에 따른 차이

## 많은 임시 객체를 만드는 코드 vs 오래 살아남는 객체를 만드는 코드
1. 어떤 쪽이 GC에 더 큰 부담을 주는가?
	1. 

## Stop the World 딜레마 - 자주 발생하는 짧은 정지 vs 가끔 발생하는 긴 정지
1. 실제 애플리케이션에서는 어떤 게 더 문제가 되는가?
2. 실제 환경에서의 사례
	1. 짧은 정지 여러번 전략
		1. 웹 서버, API 서버: 사용자가 응답 지연을 직접 체감하는 경우
		2. 실시간 게임 서버: 100ms+ 정지하면 플레이어가 렉을 느낌
		3. 모바일 백엔드: 네트워크 지연과 GC 지연이 누적되면 UX 악화
		4. 금융 거래 시스템: 밀리초 단위 지연으로 비즈니스에 막대한 영향
	2. 긴 정지 한번 전략
		1. 배치 처리: 밤에 대량의 데이터 처리, 사용자 대기 없음
		2. 데이터 분석: 10분 작업에서 3초 정지는 무시 가능한 수준
		3. 빌드/배포 시스템: 전체 처리량이 중요하지 정지 횟수나 시간은 상관 없음
		4. ETL 작업: 대용량 처리에서는 GC 효율이 더 중요함
3. 결론
	1. 결국 트레이드 오프가 강제됨
		1. 지연 민감한 서비스 -> 짧은 정지를 자주 (응답성 우선)
		2. 처리량 중심 서비스 -> 긴 정지도 OK (효율성 우선) 	

## 제어 가능한 스택 오버플로우
1. 재귀함수로 인해 스택 오버플로우가 예상될 경우
	1. 메모이제이션이 스택 오버플로우를 줄이는데 도움이 될 수 있을까?
		1. 생각
			1. 메서드콜 횟수는 줄어들긴 하는데 depth를 획기적으로 줄여준다는 보장은 없음
			2. 콜 횟수 감소로 스택은 적게 쌓이지만 대신 그만큼 힙을 더 점유하지 않는가?
		2. 결론
			1. 한번 계산한 결과를 캐싱하여 같은 인풋에 대해 다시 계산하지 않는다는 개념
			2. 예상대로 전체 콜 횟수는 줄어드나, 유의미한 depth 감소는 없음
			3. 연산 횟수를 획기적으로 줄여 러닝타임동안 스택의 점유율이 낮아지는것은 사실
			4. 간접적인 효과만 제한적으로 있다